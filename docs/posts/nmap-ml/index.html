<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="author" content="Alban Siffer">
<meta name="description" content="Yes, the most famous network scanner embeds Machine Learning. Really? A deep neural network with many scientific keywords ? Not at all, I&#39;m more talking about *grandpa* machine learning. Let us discover it!" />
<meta name="keywords" content=", nmap, Machine Learning" />
<meta name="robots" content="noodp" />
<meta name="theme-color" content="" />
<link rel="canonical" href="https://asiffer.github.io/posts/nmap-ml/" />


    <title>
        
            Machine Learning in Nmap :: Alban Siffer 
        
    </title>



<link href="https://cdnjs.cloudflare.com/ajax/libs/flag-icon-css/3.5.0/css/flag-icon.min.css" rel="stylesheet"
    type="text/css">



<link rel="stylesheet" href="/main.d7bdd8ee18bfbf4c605488a7e5b1b92cd980dfeed2bdaeab4dd5e931a7a78bc0.css">


    
        <link rel="stylesheet" type="text/css" href="/css/nord.css">
    

    
        <link rel="stylesheet" type="text/css" href="/css/custom.css">
    





<meta itemprop="name" content="Machine Learning in Nmap">
<meta itemprop="description" content="Yes, the most famous network scanner embeds Machine Learning. Really? A deep neural network with many scientific keywords ? Not at all, I&#39;m more talking about *grandpa* machine learning. Let us discover it!">
<meta itemprop="datePublished" content="2019-06-17T00:00:00+00:00" />
<meta itemprop="dateModified" content="2019-06-17T00:00:00+00:00" />
<meta itemprop="wordCount" content="2243">



<meta itemprop="keywords" content="nmap,Machine Learning," />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Machine Learning in Nmap"/>
<meta name="twitter:description" content="Yes, the most famous network scanner embeds Machine Learning. Really? A deep neural network with many scientific keywords ? Not at all, I&#39;m more talking about *grandpa* machine learning. Let us discover it!"/>








    <meta property="article:published_time" content="2019-06-17 00:00:00 &#43;0000 UTC" />








    </head>

    
        <body>
    
    
        <div class="container">
            <header class="header">
    <span class="header__inner">
        <a href="/" style="text-decoration: none;">
    <div class="logo">
        
            <span class="logo__mark">#</span>
            <span class="logo__text">cd /home/∇</span>
            <span class="logo__cursor" style=
                  "
                   
                   ">
            </span>
        
    </div>
</a>


        <span class="header__right">
            
                <nav class="menu">
    <ul class="menu__inner"><li><a href="/about/">about</a></li><li><a href="/research/">research</a></li><li><a href="/software/">software</a></li><li><a href="/posts/">posts</a></li>
    </ul>
</nav>

                <span class="menu-trigger">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                        <path d="M0 0h24v24H0z" fill="none"/>
                        <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                    </svg>
                </span>
            
        </span>
    </span>
</header>


            <div class="content">
                
  <main class="post">

    <div class="post-info">
      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-clock">
          <circle cx="12" cy="12" r="10"></circle>
          <polyline points="12 6 12 12 16 14"></polyline>
        </svg>
        11 minutes

        
      </p>
    </div>

    <article>
      <h1 class="post-title">
        <a href="https://asiffer.github.io/posts/nmap-ml/">Machine Learning in Nmap</a>
      </h1>

      
        <div class="post-excerpt">Yes, the most famous network scanner embeds Machine Learning. Really? A deep neural network with many scientific keywords ? Not at all, I&#39;m more talking about *grandpa* machine learning. Let us discover it!</div>
      

      
        <hr />
        <aside id="toc">
          <div class="toc-title">Table of Contents</div>
          <nav id="TableOfContents">
  <ul>
    <li><a href="#first-discovery">First discovery</a></li>
    <li><a href="#deep-learning">Deep learning</a></li>
    <li><a href="#coming-back-to-nmap">Coming back to Nmap</a></li>
    <li><a href="#a-fingerprint-model">A fingerprint model</a></li>
    <li><a href="#classifying-the-fingerprint">Classifying the fingerprint</a></li>
    <li><a href="#what-does-liblinear-do-exactly">What does liblinear do exactly?</a></li>
    <li><a href="#best-does-not-mean-right">Best does not mean right</a></li>
    <li><a href="#conclusion">Conclusion</a></li>
    <li><a href="#ideas-to-improve-nmap">Ideas to improve NMAP</a></li>
  </ul>
</nav>
        </aside>
        <hr />

      <div class="post-content">
        <hr>
<p><strong>Notes</strong></p>
<ul>
<li>The original post has been published on the <a href="https://blog.amossys.fr/nmap-ml.html">Amossys blog</a></li>
<li>I present some pieces of codes which are originally commented by their authors. I keep authors&rsquo; comments under the format <code>/* comments */</code> while my own comments use the format <code>// comments</code>.</li>
<li>I use the version <strong>7.70SVN</strong> of <code>nmap</code>.</li>
</ul>
<hr>
<h2 id="first-discovery">First discovery</h2>
<p>After installing a basic Raspbian on my RPi, I also decided to add <code>nmap</code> to the system. Not so hard&hellip; but I was quite amazed.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ sudo apt install nmap
...
The following additional packages will be installed:
  liblinear3 liblua5.3-0 ndiff python-bs4 python-html5lib python-lxml
  python-webencodings
...
</code></pre></div><p>The package manager demands other packages, especially lua and python stuff. Ok, why not, but why <code>liblinear3</code> ?!
Actually, <code>liblinear</code> is a library for linear classification. Hum&hellip; it looks weird, so I decided to go deeper!</p>
<h2 id="deep-learning">Deep learning</h2>
<p>Sorry for the pun, but there is not any neural network behind that.
Looking at the code of <code>liblinear</code>, available on <a href="https://github.com/cjlin1/liblinear">GitHub</a>, we basically learn the following:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-markdown" data-lang="markdown">LIBLINEAR is a simple package for solving large-scale regularized linear
classification and regression. It currently supports
<span style="color:#66d9ef">-</span> L2-regularized logistic regression/L2-loss support vector classification/L1-loss support vector classification
<span style="color:#66d9ef">-</span> L1-regularized L2-loss support vector classification/L1-regularized logistic regression
<span style="color:#66d9ef">-</span> L2-regularized L2-loss support vector regression/L1-loss support vector regression.
</code></pre></div><p>In a word, it can do three things:</p>
<ul>
<li>logistic regression</li>
<li>support vector classification</li>
<li>support vector regression</li>
</ul>
<p>Even if the first technique aimed to fit data to a model, it is mainly used to perform binary classification.
The code boils down to few files:</p>
<ul>
<li><code>linear.h</code></li>
<li><code>tron.h</code></li>
</ul>
<div class="info">
    The whole implementation is probably very efficient as <code>liblinear</code> won the ICML 2008 large-scale learning challenge and has been used to win the KDD Cup 2010 (see <a href="https://www.csie.ntu.edu.tw/~cjlin/liblinear/)">https://www.csie.ntu.edu.tw/~cjlin/liblinear/)</a>.
</div>
<h2 id="coming-back-to-nmap">Coming back to Nmap</h2>
<p>Now, the goal is to look for <code>liblinear</code> inside the <code>nmap</code> code (about 85Mb).</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ git clone https://github.com/nmap/nmap.git
</code></pre></div><p>The natural idea is to <em>grep</em> &ldquo;linear.h&rdquo; in the folder.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ cd nmap
$ grep -r linear.h  
liblinear/Makefile:linear.o: linear.cpp linear.h
liblinear/liblinear.vcxproj:    &lt;ClInclude Include<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;linear.h&#34;</span> /&gt;
liblinear/Makefile.win:linear.obj: linear.cpp linear.h
liblinear/Makefile.win:lib: linear.cpp linear.h linear.def tron.obj
liblinear/linear.cpp:#include <span style="color:#e6db74">&#34;linear.h&#34;</span>
liblinear/predict.c:#include <span style="color:#e6db74">&#34;linear.h&#34;</span>
liblinear/train.c:#include <span style="color:#e6db74">&#34;linear.h&#34;</span>
FPModel.cc:#include <span style="color:#e6db74">&#34;linear.h&#34;</span>
configure.ac:  AC_CHECK_HEADERS<span style="color:#f92672">([</span>linear.h<span style="color:#f92672">]</span>,
FPEngine.cc:#include <span style="color:#e6db74">&#34;linear.h&#34;</span>
configure:  <span style="color:#66d9ef">for</span> ac_header in linear.h
configure:  ac_fn_c_check_header_mongrel <span style="color:#e6db74">&#34;</span>$LINENO<span style="color:#e6db74">&#34;</span> <span style="color:#e6db74">&#34;linear.h&#34;</span> <span style="color:#e6db74">&#34;ac_cv_header_linear_h&#34;</span> <span style="color:#e6db74">&#34;</span>$ac_includes_default<span style="color:#e6db74">&#34;</span>
configure:if test <span style="color:#e6db74">&#34;x</span>$ac_cv_header_linear_h<span style="color:#e6db74">&#34;</span> <span style="color:#f92672">=</span> xyes; <span style="color:#66d9ef">then</span> :
</code></pre></div><p>The result shows a dozen of occurrences. The &ldquo;configure&rdquo; file is not interesting. The occurrences inside <code>liblinear/</code> are not relevant as <code>nmap</code> stores the library code inside it. Finally we have two source code files <code>FPModel.cc</code> and <code>FPEngine.cc</code> which draw our attention (&lsquo;FP&rsquo; means &lsquo;finger-printing&rsquo;).
In the folder we can also find two headers <code>FPModel.h</code> and <code>FPEngine.h</code>.</p>
<p>In <code>FPModel.h</code>, five objects are introduced.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#66d9ef">extern</span> <span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">model</span> FPModel;
<span style="color:#66d9ef">extern</span> <span style="color:#66d9ef">double</span> FPscale[][<span style="color:#ae81ff">2</span>];
<span style="color:#66d9ef">extern</span> <span style="color:#66d9ef">double</span> FPmean[][<span style="color:#ae81ff">695</span>];
<span style="color:#66d9ef">extern</span> <span style="color:#66d9ef">double</span> FPvariance[][<span style="color:#ae81ff">695</span>];
<span style="color:#66d9ef">extern</span> FingerMatch FPmatches[];
</code></pre></div><p>The <code>FPEngine.h</code> is quite richer and notably defines an <code>FPEngine</code> object</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#75715e">/* This class is the generic fingerprinting engine. */</span>
<span style="color:#66d9ef">class</span> <span style="color:#a6e22e">FPEngine</span> {

<span style="color:#66d9ef">protected</span><span style="color:#f92672">:</span>
  size_t osgroup_size;

<span style="color:#66d9ef">public</span><span style="color:#f92672">:</span>
  FPEngine();
  <span style="color:#f92672">~</span>FPEngine();
  <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">reset</span>();
  <span style="color:#66d9ef">virtual</span> <span style="color:#66d9ef">int</span> <span style="color:#a6e22e">os_scan</span>(std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span>Target <span style="color:#f92672">*&gt;</span> <span style="color:#f92672">&amp;</span>Targets) <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
  <span style="color:#66d9ef">const</span> <span style="color:#66d9ef">char</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">bpf_filter</span>(std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span>Target <span style="color:#f92672">*&gt;</span> <span style="color:#f92672">&amp;</span>Targets);

};
</code></pre></div><p>Looking at the methods of <code>FPEngine</code>, we start to understand the purpose of <code>liblinear</code>: OS detection, which is a very nice and powerful feature in practice, isn&rsquo;t it?</p>
<h2 id="a-fingerprint-model">A fingerprint model</h2>
<p>While the header <code>FPModel.h</code> is rather small, the objects it declares are really heavy! They are all implemented in <code>FPModel.cc</code>.
In particular the <code>FPModel</code> structure is an instance of a <code>model</code> defined in <code>liblinear.h</code>:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">model</span>
{
	<span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">parameter</span> param;
	<span style="color:#66d9ef">int</span> nr_class;		<span style="color:#75715e">/* number of classes */</span>
	<span style="color:#66d9ef">int</span> nr_feature;
	<span style="color:#66d9ef">double</span> <span style="color:#f92672">*</span>w;
	<span style="color:#66d9ef">int</span> <span style="color:#f92672">*</span>label;		<span style="color:#75715e">/* label of each class */</span>
	<span style="color:#66d9ef">double</span> bias;
};
</code></pre></div><p>The FPModel has the following attribute values:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">model</span> FPModel <span style="color:#f92672">=</span> {
	{<span style="color:#ae81ff">0</span>},			<span style="color:#75715e">// L2R_LR solver 
</span><span style="color:#75715e"></span>                    <span style="color:#75715e">// (L2-regularized classifiers 
</span><span style="color:#75715e"></span>                    <span style="color:#75715e">// and logistic regression)
</span><span style="color:#75715e"></span>	<span style="color:#ae81ff">96</span>, 			<span style="color:#75715e">// number of classes
</span><span style="color:#75715e"></span>	<span style="color:#ae81ff">695</span>,			<span style="color:#75715e">// number of features
</span><span style="color:#75715e"></span>	_w,			    <span style="color:#75715e">// weights (695 x 96 values)
</span><span style="color:#75715e"></span>	_labels,		<span style="color:#75715e">// index of the classes ([0, 1 ..., 95])
</span><span style="color:#75715e"></span>	<span style="color:#f92672">-</span><span style="color:#ae81ff">1.00000000</span> 	<span style="color:#75715e">// -1 means no bias
</span><span style="color:#75715e"></span>};
</code></pre></div><p><strong>What do we learn?</strong> Nmap embeds a classification task. For every observation, i.e. a vector of size 695 (695 features), the goal is to find the class that best matches it among the 96 available.</p>
<p><strong>What are the observations?</strong> Basically, they are the fingerprints. They are represented by 695 features.</p>
<p><strong>What are the features?</strong> The 695 values are the results of network scanning.</p>
<p><strong>What are the classes?</strong> The array <code>FPmatches</code> notably details the 96 classes: they are OS with specific version (for instance we have &ldquo;Linux 2.6.11 - 2.6.15&rdquo; and &ldquo;Linux 2.6.32 - 2.6.39&rdquo; but also &ldquo;Netgear DGN3300v2 ADSL router&rdquo;).</p>
<p>Currently, we don&rsquo;t know exactly how the classification is performed, but it will basically use the local variable <code>_w</code> which is a big weights array. In a word, we can say that the classification model is stored in <code>_w</code>.</p>
<p>Three structures have not been unveiled: <code>FPscale</code>, <code>FPmean</code> and <code>FPvariance</code>. Let us have a look to the first:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#75715e">/* Scale parameters are pairs (a, b). A scaled value x&#39; is calculated from
</span><span style="color:#75715e">   a, b, and an observed x by x&#39; = (x + a) * b. */</span>
<span style="color:#66d9ef">double</span> FPscale[][<span style="color:#ae81ff">2</span>] <span style="color:#f92672">=</span> {
	{        <span style="color:#f92672">-</span><span style="color:#ae81ff">20</span>,  <span style="color:#ae81ff">0.0416667</span> },	<span style="color:#75715e">/* S1.PLEN */</span>
	{         <span style="color:#f92672">-</span><span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0.00520833</span> },	<span style="color:#75715e">/* S1.TC */</span>
	{        <span style="color:#f92672">-</span><span style="color:#ae81ff">64</span>,  <span style="color:#ae81ff">0.0052356</span> },	<span style="color:#75715e">/* S1.HLIM */</span>
	{        <span style="color:#f92672">-</span><span style="color:#ae81ff">20</span>,  <span style="color:#ae81ff">0.0416667</span> },	<span style="color:#75715e">/* S2.PLEN */</span>
	{         <span style="color:#f92672">-</span><span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0.00520833</span> },	<span style="color:#75715e">/* S2.TC */</span>
        ...
</code></pre></div><p>The structure is a 695x2 matrix. At each line, a comment describes a quantitative feature used for OS detection. The values inside a row aim to &ldquo;scale&rdquo; the value of the feature.</p>
<div class="info">
    When we want to classify data according to some features, it is often relevant to balance their impact. In particular, if a feature lies between 1000 and 10000, it is likely to carry more weight during the classifier training than a feature stuck between 0 and 1. Therefore, features are &ldquo;scaled&rdquo; to make them lie in the same range.
</div>
<p>Even if the use of these coefficients <code>a</code> and <code>b</code> are weird (I would rather use a mean and a standard deviation), they do the job (the author&rsquo;s comment details how features are scaled).</p>
<p><code>FPscale</code> normalizes the data, so&hellip; what is the purpose of <code>FPmean</code> and <code>FPvariance</code> ??! We will see that later.</p>
<h2 id="classifying-the-fingerprint">Classifying the fingerprint</h2>
<p>While <code>FPModel.cc</code> gathers data, detection procedures are implemented in <code>FPEngine.cc</code>. The function we are interested in is:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#66d9ef">static</span> <span style="color:#66d9ef">void</span> classify(FingerPrintResultsIPv6 <span style="color:#f92672">*</span>FPR)
</code></pre></div><p>Here we see a specificity: <code>nmap</code> uses this ML process only to classify IPv6 fingerprints. For IPv4 fingerprints, it actually tests them against fingerprint references (you can find at <code>/usr/share/nmap/nmap-os-db</code>). More details can be found at <a href="https://nmap.org/book/osdetect-guess.html#osdetect-guess-ipv4">OS Matching Algorithm</a>.</p>
<p>The <code>classify</code> function takes a fingerprint as input and stores the basic classification result inside the <code>FPR-&gt;overall_results</code> attribute (<code>OSSCAN_NOMATCHES</code> or <code>OSSCAN_SUCCESS</code>). More elements are stored in other attributes like <code>FPR-&gt;matches</code> or <code>FPR-&gt;accuracy</code>. Let us describe how this function treats a fingerprint:</p>
<p>First, it retrieves the features from the fingerprint itself:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp">features <span style="color:#f92672">=</span> vectorize(FPR);
</code></pre></div><p>Then features are scaled:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp">apply_scale(features, get_nr_feature(<span style="color:#f92672">&amp;</span>FPModel), FPscale);
</code></pre></div><p>Finally some scores are computed by the algorithms inside <code>liblinear</code>. Every score estimates the similarity between the current fingerprint (<code>features</code>) and a given OS.
As these scores come from a logistic regression, they can be turned into probabilities.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp">predict_values(<span style="color:#f92672">&amp;</span>FPModel, features, values);
  <span style="color:#66d9ef">for</span> (i <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>; i <span style="color:#f92672">&lt;</span> nr_class; i<span style="color:#f92672">++</span>) {
    labels[i].label <span style="color:#f92672">=</span> i;
    labels[i].prob <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.0</span> <span style="color:#f92672">/</span> (<span style="color:#ae81ff">1.0</span> <span style="color:#f92672">+</span> exp(<span style="color:#f92672">-</span>values[i]));
  }
</code></pre></div><p>All these probabilities are then sorted in descending order.
The OS giving the highest one is considered as a <em>perfect match</em>. Moreover, all the OS getting a probability higher that 90% of the highest probability are also considered as perfect matches.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#66d9ef">if</span> (labels[i].prob <span style="color:#f92672">&gt;=</span> <span style="color:#ae81ff">0.90</span> <span style="color:#f92672">*</span> labels[<span style="color:#ae81ff">0</span>].prob)
      FPR<span style="color:#f92672">-&gt;</span>num_perfect_matches <span style="color:#f92672">=</span> i <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>;
</code></pre></div><p>After checking all the scores, the code looks at the number of perfect matches. If there is not exactly one perfect match, <code>OSSCAN_NOMATCHES</code> is set (meaning that OS has not been detected). It is rather strange because if we have two or more matches, we unfortunately get no result.
However, this event could possibly not happen once classes are well separated.</p>
<h2 id="what-does-liblinear-do-exactly">What does liblinear do exactly?</h2>
<p>As we said <code>liblinear</code> provides several solvers to perform linear regression/classification. <code>nmap</code> uses a regularized logistic regression to classify fingerprints. Logistic regression is basically used for a 2-classes classification task, but it can be extended to greater number of classes with a <em>one-versus-all</em> approach (this is what <code>liblinear</code> does).</p>
<div class="info">
    Let us consider a classification problem with <code>k</code> classes. The one-versus-all strategy consists in building <code>k</code> binary classifiers. The binary classifier <code>i</code> tries to separate the observations belonging to the class <code>i</code> from all the other observations.
When a new observation has to be classified, each classifier can provide the probability <code>p_i</code> that it belongs to the class <code>i</code>. The class with maximum probability is naturally kept.*
</div>
<h2 id="best-does-not-mean-right">Best does not mean right</h2>
<p>The function <code>classify</code> actually goes deeper as it performs another check on the best found OS. Precisely, it calls the function <code>novelty_of</code> and check its output:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp">novelty <span style="color:#f92672">=</span> novelty_of(features, labels[<span style="color:#ae81ff">0</span>].label);
...
<span style="color:#66d9ef">if</span> (novelty <span style="color:#f92672">&lt;</span> FP_NOVELTY_THRESHOLD) {
      FPR<span style="color:#f92672">-&gt;</span>overall_results <span style="color:#f92672">=</span> OSSCAN_SUCCESS;
    } <span style="color:#66d9ef">else</span> {
      ...
      FPR<span style="color:#f92672">-&gt;</span>overall_results <span style="color:#f92672">=</span> OSSCAN_NOMATCHES;
	  ...
    }
</code></pre></div><p><strong>What does this function do?</strong> It actually computes a distance between our observation (<code>features</code>) and the group of all the observations belonging the predicted class (given through <code>labels[0].label</code>).</p>
<p>For that purpose, it uses&hellip; <code>FPmean</code> and <code>FPVariance</code> structures! They are merely 96x695 matrices where <code>FPmean[i][j]</code> represents the mean of the feature <code>j</code> for the OS <code>i</code> (<code>FPvariance</code> gives the corresponding variance).</p>
<p>Actually, the computed distance looks like the <a href="https://en.wikipedia.org/wiki/Mahalanobis_distance">Mahalanobis distance</a> except that it does not take into account the correlation between features. In a way, it assumes that there is no linear relation between the features (a stronger assumption would be that they are indepedent): for sure this is a wrong assumption but it does not prevent it from working in practice.</p>
<div class="info">
    The code is well documented and authors give many details about this function. In particular, they explain they use this approximation to <em>save space</em>.
</div>
<p>As we see, it uses a harcoded threshold, defined in <code>FPEngine.h</code>:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#75715e">#define FP_NOVELTY_THRESHOLD 15.0
</span></code></pre></div><p>Eventually, the whole approach is rather relevant: the fingerprint is compared to all the OS. The &ldquo;closest&rdquo; OS (the one with highest probability) is kept but we ensure that the fingerprint is not too far from other observations sharing this OS.</p>
<h2 id="conclusion">Conclusion</h2>
<p>OS detection is obviously a powerful feature of <code>nmap</code>, that is also why we could be curious to know how it works. While IPv4 fingerprints are basically tested against some references, a ML-based approach is used to classify IPv6 ones.</p>
<p>Forget about fancy deep stuff algorithms! <code>nmap</code> uses a logistic regression to estimate the probability of a fingerprint to belong to a certain class (OS). Furthermore, it computes a novelty score which aims to avoid misclassification.
The whole process is summed up below (for official details, you can look at <a href="https://nmap.org/book/osdetect-guess.html#osdetect-guess-ipv6">IPv6 Matching</a> )</p>
<p>
    <img src="/images/nmap/nmap.png"  class="left"  />


<div class="caption">
    Figure 1: IPv6 OS detection process in <code>nmap</code>
</div></p>
<p>Despite its practical efficiency, we can do a couple of remarks:</p>
<ul>
<li>The model (all the blue elements) is totally static, a bit crude (raw values) and hard to enrich by ourself.</li>
<li>Some aspects are more about hacking: uncommon pipeline, use of hardcoded constants and strange choices (about the number of matches especially).</li>
</ul>
<p>I personnally think that we could improve the whole detection engine (using also an ML approach for IPv4). The key elements would be to use a more flexible design and to set up a more &ldquo;modern&rdquo; detection workflow (to try it at least). I develop some of these ideas in the last paragraph.</p>
<h2 id="ideas-to-improve-nmap">Ideas to improve NMAP</h2>
<p>The built-in <code>nmap</code> model is very powerful as it takes into account almost hundred OS. However it is static and possibly updated only when a new version is available.</p>
<p>Imagine you have fingerprints of very uncommon systems like SCADA or seldom firmwares. You have to submit this fingerprint to update the whole model (updating the model locally is rather hard). You possibly don&rsquo;t want to share your fingerprints or even you are very motivated, it will take time as we can see in that <a href="https://superuser.com/a/1099650">post</a> of <a href="http://bonsaiviking.com/">Daniel Miller</a>:</p>
<blockquote>
<p>[&hellip;] integrating user-submitted fingerprints is a manual process that takes several weeks of dedicated time to accomplish each year. We (the Nmap developers) are always looking for ways to improve this process and make more frequent updates, but generally there are only 2 releases per year.</p>
</blockquote>
<p>So the idea would be to have a more dynamic model that every <code>nmap</code> user can enrich (interactively for instance) and possibly share. A solution would be to have a fingerprint database. Yes, it already exists: <code>/usr/share/nmap/nmap-os-db</code>, but this is for IPv4 fingerprints. Moreover fingerprints should be stored directly as a feature vector. Thus, the model could be easily rebuilt by the user.</p>
<p>Furthermore, the current process computes the novelty of a new fingerprint but this piece of information is not exploited either while it could improve our detection engine.</p>
<p><strong>Can we use a even more powerful workflow?</strong> It is hard to talk about the choice of the algorithms. The number of features is quite high (695), but even if <code>liblinear</code> is made for large scale datasets, I would rather have a look to other classifiers like <a href="https://en.wikipedia.org/wiki/Random_forest">Random Forest</a> which does not need scaled data, may select the most relevant features and fits all the classes at the same time (no one-versus-all approach). About novelty detection, the computed distance is a bit uncommon. From the random forest classifier, it is possible to set a kind of &ldquo;certainty threshold&rdquo; below which the fingerprint is not classified. Another way would be to compute the <a href="https://en.wikipedia.org/wiki/Local_outlier_factor">Local Outlier Factor</a> (LOF) to check if the fingerprint looks like its neighbours (but it requires several labeled samples).</p>

      </div>
    </article>

    <hr />

    <div class="post-info">
      
    <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line></svg>

        <span class="tag"><a href="https://asiffer.github.io/tags/nmap/">nmap</a></span>
        <span class="tag"><a href="https://asiffer.github.io/tags/machine-learning/">Machine Learning</a></span>
        
    </p>

      

      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text">
          <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path>
          <polyline points="14 2 14 8 20 8"></polyline>
          <line x1="16" y1="13" x2="8" y2="13"></line>
          <line x1="16" y1="17" x2="8" y2="17"></line>
          <polyline points="10 9 9 9 8 9"></polyline>
        </svg>
        2243 Words
      </p>

      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar">
          <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect>
          <line x1="16" y1="2" x2="16" y2="6"></line>
          <line x1="8" y1="2" x2="8" y2="6"></line>
          <line x1="3" y1="10" x2="21" y2="10"></line>
        </svg>
        
          2019-06-17 02:00
        

         
          
        
      </p>
    </div>

    
      <div class="pagination">
        <div class="pagination__title">
          <span class="pagination__title-h"></span>
          <hr />
        </div>

        <div class="pagination__buttons">
          
            <span class="button previous">
              <a href="https://asiffer.github.io/posts/numpy/">
                <span class="button__icon">←</span>
                <span class="button__text">Passing numpy array to shared library</span>
              </a>
            </span>
          

          
            <span class="button next">
              <a href="https://asiffer.github.io/posts/threat-intel/">
                <span class="button__text">Fancy Threat Intel&#39; with Cowrie/MySQL/Grafana stack</span>
                <span class="button__icon">→</span>
              </a>
            </span>
          
        </div>
      </div>
    


    

    

  </main>

            </div>

            
                <footer class="footer">
    <div class="footer__inner">
        <div class="footer__content">
            <span>&copy; 2021</span>
            
            <span><a href="https://asiffer.github.io/posts/index.xml" target="_blank" title="rss"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 20 20" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-rss"><path d="M4 11a9 9 0 0 1 9 9"></path><path d="M4 4a16 16 0 0 1 16 16"></path><circle cx="5" cy="19" r="1"></circle></svg></a></span>
        </div>
    </div>
    <div class="footer__inner">
        <div class="footer__content">
            <span>Powered by <a href="http://gohugo.io">Hugo</a></span>
            <span>Made with &#10084; by <a href="https://github.com/rhazdon">Djordje Atlialp</a></span>
          </div>
    </div>
</footer>

            
        </div>

        



<script type="text/javascript" src="/bundle.min.af435e44374f1e99a669ea8cd5bb9a2fceed80588941a451bfddb66b86a67c9f40b0f417e9543a763f809aa7e9300d7b1d69bf99615810ba02ac70396d50fad5.js" integrity="sha512-r0NeRDdPHpmmaeqM1buaL87tgFiJQaRRv922a4amfJ9AsPQX6VQ6dj&#43;AmqfpMA17HWm/mWFYELoCrHA5bVD61Q=="></script>



    </body>
</html>
